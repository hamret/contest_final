# -*- coding: utf-8 -*-
"""
zero_shot_classify_v8_stop1000.py
---------------------------------
âœ… ëª¨ë“  ì‹œíŠ¸ ë³‘í•© + 3ë¼ë²¨ ì œë¡œìƒ· ë¶„ë¥˜
âœ… ë¼ë²¨ 1(ê°œì¸ì˜ê²¬)ì´ 1000ê°œ ë„ë‹¬ ì‹œ ìë™ ì¤‘ë‹¨
âœ… í”„ë¡œì íŠ¸ í´ë”ì—ì„œ SOCIAL_ íŒŒì¼ ìë™ ê²€ìƒ‰ (ì—¬ëŸ¬ íŒŒì¼ ìˆœì°¨ ì²˜ë¦¬)
âœ… ì¶œë ¥ íŒŒì¼ëª…ì— _labeled ìë™ ì¶”ê°€
"""

import argparse
import os
import glob
import pandas as pd
from tqdm import tqdm
from transformers import pipeline

# =============================
# ğŸ”¹ ë¼ë²¨ ì •ì˜
# =============================
CANDIDATE_LABELS = [
    "ì´ ë¬¸ì¥ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë‚˜ ë³´ë„ë¬¸ì²˜ëŸ¼ ê°ê´€ì ì¸ ì‚¬ì‹¤ì„ ì „ë‹¬í•œë‹¤. ì£¼ê´€ì ì¸ ì˜ê²¬ì´ë‚˜ ê°ì • í‘œí˜„ ì—†ì´, ì‚¬ê±´, ì¸ë¬¼, í˜ì˜, ì¡°ì¹˜ ë“±ì˜ ì •ë³´ë¥¼ ì¤‘ë¦½ì ìœ¼ë¡œ ê¸°ìˆ í•œë‹¤.",
    "ì´ ë¬¸ì¥ì€ ê°œì¸ì´ ìì‹ ì˜ ìƒê°, íŒë‹¨, ì£¼ì¥, ë¹„íŒ ë˜ëŠ” ì‚¬íšŒì  í–‰ë™ ì°¸ì—¬ ì˜ì‚¬ë¥¼ í‘œí˜„í•œë‹¤. ë°˜ë“œì‹œ ê°•í•œ ê°ì •ì´ ë“œëŸ¬ë‚˜ì§€ ì•Šì•„ë„, ì˜ê²¬ì´ë‚˜ í•´ì„ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê°œì¸ ì˜ê²¬ìœ¼ë¡œ ë³¸ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë¶„ë…¸, ì‘ì›, ì²­ì›, íƒ„ì›, ì§€ì§€, í‰ê°€ ë“±ì˜ í‘œí˜„ì´ ì´ì— í•´ë‹¹í•œë‹¤.",
    "ì´ ë¬¸ì¥ì€ ì•„ë™ë³µì§€ë²•ì´ë‚˜ ì‚¬ê±´ì˜ ë³¸ì§ˆê³¼ ê´€ë ¨ì´ ì—†ê±°ë‚˜, ë‹¨ìˆœ ì–¸ê¸‰, ì¡ë‹´, íšŒì˜ì  í‘œí˜„ ë“±ìœ¼ë¡œ ì˜ë¯¸ê°€ ë¶ˆë¶„ëª…í•˜ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'ê¸€ì„', 'ã…‹ã…‹', 'ê·¸ëƒ¥' ë“±ì˜ í‘œí˜„ì´ í¬í•¨ëœë‹¤."
]
HYPOTHESIS_TEMPLATE = "ë‹¤ìŒ ë¬¸ì¥ì€ {}."


# =============================
# ğŸ”¹ Excel íŒŒì¼ ìë™ ê²€ìƒ‰
# =============================
def find_excel_files(project_dir=None):
    """í”„ë¡œì íŠ¸ í´ë”ì—ì„œ SOCIAL_ íŒ¨í„´ì˜ Excel íŒŒì¼ë“¤ì„ ê²€ìƒ‰"""
    if project_dir is None:
        project_dir = os.getcwd()

    print(f"[INFO] í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬: {project_dir}")

    # ë¨¼ì € íŠ¹ì • íŒŒì¼ë“¤ì„ ì§ì ‘ í™•ì¸
    specific_files = [
        os.path.join(project_dir, "SOCIAL_ê°œì¸ì •ë³´ë³´í˜¸ë²•_ì „ì²˜ë¦¬_v4_cleaned.xlsx"),
        os.path.join(project_dir, "SOCIAL_ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²•_ì „ì²˜ë¦¬_v4_cleaned.xlsx")
    ]

    excel_files = [f for f in specific_files if os.path.exists(f)]

    if not excel_files:
        # SOCIAL_ë¡œ ì‹œì‘í•˜ëŠ” xlsx íŒŒì¼ ê²€ìƒ‰
        pattern = os.path.join(project_dir, "SOCIAL_*.xlsx")
        excel_files = glob.glob(pattern)

        if not excel_files:
            # ë‹¤ë¥¸ íŒ¨í„´ë„ ì‹œë„ (í•œê¸€ íŒŒì¼ëª… í¬í•¨)
            all_excel = glob.glob(os.path.join(project_dir, "*.xlsx"))
            social_files = [f for f in all_excel if "SOCIAL" in os.path.basename(f)]
            excel_files = social_files

    print(f"[INFO] ë°œê²¬ëœ Excel íŒŒì¼ë“¤: {[os.path.basename(f) for f in excel_files]}")
    return excel_files


# =============================
# ğŸ”¹ ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
# =============================
def generate_output_filename(input_files, base_output=None):
    """ì…ë ¥ íŒŒì¼ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶œë ¥ íŒŒì¼ëª… ìƒì„± (_labeled ì¶”ê°€)"""
    if base_output:
        # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í•œ ê²½ìš°
        name, ext = os.path.splitext(base_output)
        return f"{name}_labeled{ext}"

    if len(input_files) == 1:
        # ë‹¨ì¼ íŒŒì¼ì¸ ê²½ìš° í•´ë‹¹ íŒŒì¼ëª… ê¸°ë°˜
        input_path = input_files[0]
        dir_name = os.path.dirname(input_path)
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        # _cleanedê°€ ìˆìœ¼ë©´ ì œê±°í•˜ê³  _labeled ì¶”ê°€
        if base_name.endswith("_cleaned"):
            base_name = base_name[:-8]  # "_cleaned" ì œê±°
        return os.path.join(dir_name, f"{base_name}_labeled.xlsx")
    else:
        # ë‹¤ì¤‘ íŒŒì¼ì¸ ê²½ìš° combined ì‚¬ìš©
        dir_name = os.path.dirname(input_files[0])
        return os.path.join(dir_name, "SOCIAL_ê°œì¸ì •ë³´ë³´í˜¸ë²•_ì „ì²˜ë¦¬_v4_labeled.xlsx")


# =============================
# ğŸ”¹ Zero-shot ë¶„ë¥˜ê¸° ìƒì„±
# =============================
def build_classifier(model_name="joeddav/xlm-roberta-large-xnli", device=None):
    import torch
    # CUDA ìë™ ê°ì§€: ì—†ìœ¼ë©´ CPU(-1), ìˆìœ¼ë©´ ì²« GPU(0) ì‚¬ìš©
    if device is None:
        device = 0 if torch.cuda.is_available() else -1
    print(f"[INFO] ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name}, device: {device} (0=GPU, -1=CPU)")
    return pipeline(
        "zero-shot-classification",
        model=model_name,
        device=device
    )


# =============================
# ğŸ”¹ ë¬¸ì¥ ë¶„ë¥˜ í•¨ìˆ˜
# =============================
def classify_text(zsc, text):
    if not isinstance(text, str) or text.strip() == "":
        return (0.0, 0.0, 0.0, 2)
    res = zsc(
        text,
        candidate_labels=CANDIDATE_LABELS,
        hypothesis_template=HYPOTHESIS_TEMPLATE,
        multi_label=False,
    )
    scores = [dict(zip(res["labels"], res["scores"])).get(label, 0.0) for label in CANDIDATE_LABELS]
    pred_label = int(scores.index(max(scores)))
    return (*scores, pred_label)


# =============================
# ğŸ”¹ ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
# =============================
def process_single_file(input_file, zsc, text_column, target_count):
    """ë‹¨ì¼ Excel íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
    print(f"\n[INFO] íŒŒì¼ ì²˜ë¦¬ ì¤‘: {os.path.basename(input_file)}")

    # ì—¬ëŸ¬ ì‹œíŠ¸ ë³‘í•©
    xls = pd.ExcelFile(input_file)
    print(f"[INFO] ì‹œíŠ¸ ëª©ë¡: {xls.sheet_names}")

    df_list = []
    for sheet_name in xls.sheet_names:
        temp_df = pd.read_excel(xls, sheet_name=sheet_name)
        if text_column not in temp_df.columns:
            print(f"[WARN] {sheet_name} ì‹œíŠ¸ì— '{text_column}' ì—†ìŒ â†’ ê±´ë„ˆëœ€")
            continue
        temp_df = temp_df[temp_df[text_column].notna()]
        if len(temp_df) == 0:
            print(f"[WARN] {sheet_name} ì‹œíŠ¸ì— ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ â†’ ê±´ë„ˆëœ€")
            continue
        temp_df["source_sheet"] = sheet_name
        temp_df["source_file"] = os.path.basename(input_file)  # íŒŒì¼ ì •ë³´ ì¶”ê°€
        df_list.append(temp_df)
        print(f"[INFO] {sheet_name} ì‹œíŠ¸: {len(temp_df)}ê°œ ë¬¸ì¥")

    if not df_list:
        print(f"[WARN] {os.path.basename(input_file)}ì— ìœ íš¨í•œ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame(), 0, False

    df = pd.concat(df_list, ignore_index=True)
    print(f"[INFO] {os.path.basename(input_file)}: ì´ {len(df)}ê°œ ë¬¸ì¥")

    # ì‹¤ì‹œê°„ ë¶„ë¥˜ + ì¡°ê¸° ì¢…ë£Œ ì²´í¬
    results = []
    label1_count = 0
    early_stop = False

    pbar = tqdm(total=len(df), desc=f"ë¶„ë¥˜ ì¤‘ - {os.path.basename(input_file)}")

    for i, text in enumerate(df[text_column]):
        res = classify_text(zsc, str(text))
        results.append(res)

        if res[3] == 1:  # ë¼ë²¨ 1(ê°œì¸ì˜ê²¬)
            label1_count += 1

        pbar.update(1)

        if label1_count >= target_count:
            print(f"\nğŸ¯ {os.path.basename(input_file)}ì—ì„œ ë¼ë²¨1(ê°œì¸ì˜ê²¬) {label1_count}ê°œ ë„ë‹¬! â†’ ì¡°ê¸° ì¢…ë£Œ")
            df = df.iloc[: i + 1]
            early_stop = True
            break

    pbar.close()

    # ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€
    df["p_ê¸°ì‚¬ë³µì‚¬"] = [r[0] for r in results]
    df["p_ê°œì¸ì˜ê²¬"] = [r[1] for r in results]
    df["p_ë¬´ì˜ë¯¸"] = [r[2] for r in results]
    df["pred_label"] = [r[3] for r in results]
    df["pred_class"] = df["pred_label"].map({0: "ë‰´ìŠ¤ê¸°ì‚¬ë³µì‚¬", 1: "ê°œì¸ì˜ê²¬", 2: "ë¬´ì˜ë¯¸"})

    print(f"[INFO] {os.path.basename(input_file)} ì™„ë£Œ: {len(df)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ / ê°œì¸ì˜ê²¬(1): {label1_count}ê°œ")

    return df, label1_count, early_stop


# =============================
# ğŸ”¹ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================
def main():
    parser = argparse.ArgumentParser(description="ë¼ë²¨1(ê°œì¸ì˜ê²¬) 1000ê°œ ë„ë‹¬ ì‹œ ì¡°ê¸° ì¢…ë£Œ ë²„ì „ - ë‹¤ì¤‘ íŒŒì¼ ì§€ì›")
    parser.add_argument("--input", type=str, default=None, help="ì…ë ¥ íŒŒì¼ (.xlsx) - ë¯¸ì§€ì •ì‹œ ìë™ ê²€ìƒ‰")
    parser.add_argument("--project-dir", type=str, default=r"C:\Users\user\PycharmProjects\PythonProject3",
                        help="í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--text-column", type=str, default="content", help="ë¬¸ì¥ í…ìŠ¤íŠ¸ ì¹¼ëŸ¼ëª…")
    parser.add_argument("--output", type=str, default=None, help="ì¶œë ¥ íŒŒì¼ëª… (ë¯¸ì§€ì •ì‹œ ìë™ ìƒì„±)")
    parser.add_argument("--device", type=int, default=None, help="GPU index (ì˜ˆ: 0)")
    parser.add_argument("--target-count", type=int, default=1000, help="ë¼ë²¨ 1 ëª©í‘œ ê°œìˆ˜ (ê¸°ë³¸ 1000)")
    parser.add_argument("--process-all", action="store_true", help="ëª¨ë“  íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬ (ê¸°ë³¸: False)")
    args = parser.parse_args()

    # âœ… ì…ë ¥ íŒŒì¼ ê²°ì •
    if args.input is None:
        # ìë™ ê²€ìƒ‰
        excel_files = find_excel_files(args.project_dir)
        if not excel_files:
            raise FileNotFoundError("SOCIAL_*.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if len(excel_files) == 1:
            input_files = excel_files
            print(f"[INFO] ìë™ ì„ íƒëœ íŒŒì¼: {[os.path.basename(f) for f in input_files]}")
        else:
            if args.process_all:
                input_files = excel_files
                print(f"[INFO] ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ: {len(input_files)}ê°œ íŒŒì¼")
            else:
                print("[INFO] ì—¬ëŸ¬ SOCIAL_ íŒŒì¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                for i, f in enumerate(excel_files):
                    print(f"  {i + 1}. {os.path.basename(f)}")
                print(f"  {len(excel_files) + 1}. ëª¨ë“  íŒŒì¼ ì²˜ë¦¬")

                choice = input(f"ì²˜ë¦¬í•  íŒŒì¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(excel_files) + 1}): ")
                try:
                    choice_num = int(choice)
                    if choice_num == len(excel_files) + 1:
                        input_files = excel_files
                        print("[INFO] ëª¨ë“  íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                    else:
                        input_files = [excel_files[choice_num - 1]]
                except (ValueError, IndexError):
                    print("[ERROR] ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ì²« ë²ˆì§¸ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    input_files = [excel_files[0]]
    else:
        # ì§€ì •ëœ íŒŒì¼ ì‚¬ìš©
        if not os.path.isabs(args.input):
            input_file = os.path.join(args.project_dir, args.input)
        else:
            input_file = args.input

        if not os.path.exists(input_file):
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        input_files = [input_file]

    print(f"[INFO] ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜: {len(input_files)}")

    # âœ… ë¶„ë¥˜ê¸° ë¡œë“œ (í•œ ë²ˆë§Œ)
    zsc = build_classifier(device=args.device)

    # âœ… ë‹¤ì¤‘ íŒŒì¼ ìˆœì°¨ ì²˜ë¦¬
    all_results = []
    total_label1_count = 0

    for input_file in input_files:
        df_result, label1_count, early_stop = process_single_file(
            input_file, zsc, args.text_column, args.target_count - total_label1_count
        )

        if not df_result.empty:
            all_results.append(df_result)
            total_label1_count += label1_count

        # ëª©í‘œ ë‹¬ì„± ì‹œ ì „ì²´ ì¤‘ë‹¨
        if total_label1_count >= args.target_count:
            print(f"\nğŸ ì „ì²´ ëª©í‘œ ë‹¬ì„±! ì´ ë¼ë²¨1(ê°œì¸ì˜ê²¬): {total_label1_count}ê°œ")
            break

    if not all_results:
        raise ValueError("ì²˜ë¦¬í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # âœ… ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸°
    final_df = pd.concat(all_results, ignore_index=True)

    # âœ… ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì • (_labeled ìë™ ì¶”ê°€)
    output_file = generate_output_filename(input_files, args.output)

    final_df.to_excel(output_file, index=False)

    print(f"\nâœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ â†’ {output_file}")
    print(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
    print(f"  - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {len(all_results)}")
    print(f"  - ì´ ë¬¸ì¥ ìˆ˜: {len(final_df)}")
    print(f"  - ê°œì¸ì˜ê²¬(ë¼ë²¨1): {total_label1_count}ê°œ")

    # ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½
    label_counts = final_df["pred_class"].value_counts()
    for label, count in label_counts.items():
        percentage = (count / len(final_df)) * 100
        print(f"  - {label}: {count}ê°œ ({percentage:.1f}%)")


if __name__ == "__main__":
    main()